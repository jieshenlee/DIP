{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efa2a54-4054-4290-a4ec-bf13198f10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, ttk, messagebox\n",
    "from PIL import Image, ImageOps, ImageTk, ImageEnhance\n",
    "import customtkinter as ctk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import minimum_filter, maximum_filter, median_filter\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the root window\n",
    "root = ctk.CTk()  # Use CTk for the root window\n",
    "root.geometry(\"1920x1080\")\n",
    "root.title(\"Image Manipulation Tool\")\n",
    "root.config(bg=\"#f0f0f0\")\n",
    "\n",
    "pen_color = \"black\"\n",
    "pen_size = 5\n",
    "file_path = \"\"\n",
    "image_ref_original = None\n",
    "image_ref_modified = None\n",
    "\n",
    "# Store the original and modified images\n",
    "original_image = None\n",
    "modified_image = None\n",
    "\n",
    "\n",
    "\n",
    "# Function to add an image and display it\n",
    "def add_image():\n",
    "    global file_path, original_image, image_ref_original, modified_image, image_ref_modified\n",
    "    file_path = filedialog.askopenfilename(title=\"Select Image\", filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if file_path:\n",
    "        original_image = Image.open(file_path)\n",
    "        width, height = int(original_image.width / 2), int(original_image.height / 2)\n",
    "        original_image = original_image.resize((width, height), Image.Resampling.LANCZOS)\n",
    "        modified_image = original_image.copy()  # Create a copy for manipulation\n",
    "        image_ref_original = ImageTk.PhotoImage(original_image)\n",
    "        image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "\n",
    "        canvas_original.config(width=width, height=height)\n",
    "        canvas_modified.config(width=width, height=height)\n",
    "        \n",
    "        canvas_original.create_image(0, 0, image=image_ref_original, anchor=\"nw\")\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Style the input dialog with a custom theme\n",
    "def styled_input_dialog(title, prompt):\n",
    "    dialog_window = ctk.CTkToplevel(root)  # Use CTkToplevel for the dialog window\n",
    "    dialog_window.title(title)\n",
    "    \n",
    "    \n",
    "    dialog_window.grab_set()\n",
    "\n",
    "    \n",
    "    window_width, window_height = 300, 150\n",
    "    screen_width = root.winfo_screenwidth()\n",
    "    screen_height = root.winfo_screenheight()\n",
    "    x_cordinate = int((screen_width/2) - (window_width/2))\n",
    "    y_cordinate = int((screen_height/2) - (window_height/2))\n",
    "    dialog_window.geometry(f\"{window_width}x{window_height}+{x_cordinate}+{y_cordinate}\")\n",
    "    \n",
    "    dialog_window.configure(bg_color=\"#4A8\")  \n",
    "    prompt_label = ctk.CTkLabel(dialog_window, text=prompt, font=(\"Helvetica\", 12), text_color=\"white\")\n",
    "    prompt_label.pack(pady=10)\n",
    "\n",
    "    input_entry = ctk.CTkEntry(dialog_window, font=(\"Helvetica\", 12))\n",
    "    input_entry.pack(pady=10)\n",
    "\n",
    "    def on_submit():\n",
    "        dialog_window.user_input = input_entry.get()\n",
    "        dialog_window.destroy()\n",
    "\n",
    "    submit_button = ctk.CTkButton(dialog_window, text=\"Submit\", command=on_submit, font=(\"Helvetica\", 12), text_color=\"white\", fg_color=\"#333\")\n",
    "    submit_button.pack(pady=10)\n",
    "\n",
    "    root.wait_window(dialog_window)  # Wait until dialog is closed\n",
    "\n",
    "    return getattr(dialog_window, 'user_input', None)\n",
    "\n",
    "\n",
    "# Rotate the image\n",
    "def rotate_image():\n",
    "    global modified_image, image_ref_modified\n",
    "    angle = styled_input_dialog(\"Input\", \"Enter rotation angle:\")\n",
    "    if angle is not None:\n",
    "        modified_image = modified_image.rotate(float(angle), expand=True)\n",
    "        image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "        canvas_modified.config(width=modified_image.width, height=modified_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "\n",
    "# Crop the image\n",
    "def crop_image():\n",
    "    global modified_image, image_ref_modified\n",
    "    start_x, start_y = 50, 50  # Sample crop area for demonstration\n",
    "    end_x, end_y = modified_image.width - 50, modified_image.height - 50\n",
    "    modified_image = modified_image.crop((start_x, start_y, end_x, end_y))\n",
    "    image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "    canvas_modified.config(width=modified_image.width, height=modified_image.height)\n",
    "    canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "    \n",
    "def invert_colors():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        # Convert the image to a numpy array for pixel manipulation\n",
    "        array_image = np.array(modified_image)\n",
    "\n",
    "        # Invert the colors using numpy (255 - pixel value)\n",
    "        inverted_image = 255 - array_image\n",
    "\n",
    "        # Convert back to PIL format\n",
    "        inverted_image_pil = Image.fromarray(inverted_image)\n",
    "\n",
    "        # Update the modified image and display it\n",
    "        image_ref_modified = ImageTk.PhotoImage(inverted_image_pil)\n",
    "        canvas_modified.config(width=inverted_image_pil.width, height=inverted_image_pil.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "        \n",
    "        # Update the modified image to reflect the inverted colors\n",
    "        modified_image = inverted_image_pil\n",
    "\n",
    "#grayscale the image\n",
    "\n",
    "def convert_to_grayscale():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        # Convert the image to grayscale using PIL's convert method\n",
    "        grayscale_image = modified_image.convert(\"L\")  # \"L\" mode is for grayscale\n",
    "        \n",
    "        image_ref_modified = ImageTk.PhotoImage(grayscale_image)\n",
    "        canvas_modified.config(width=grayscale_image.width, height=grayscale_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "        \n",
    "        # Update the modified image to reflect grayscale\n",
    "        modified_image = grayscale_image\n",
    "\n",
    "\n",
    "#gaussian image\n",
    "def gaussian_filter():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "        \n",
    "        # Define the Gaussian filter\n",
    "        gaussian_filter = np.array([[1, 4, 7, 4, 1], \n",
    "                                    [4, 16, 26, 16, 4], \n",
    "                                    [7, 26, 41, 26, 7],\n",
    "                                    [4, 16, 26, 16, 4],\n",
    "                                    [1, 4, 7, 4, 1]], dtype=np.float32) / 273\n",
    "        \n",
    "        # Apply the Gaussian filter using cv2\n",
    "        filtered_gaussian_image = cv2.filter2D(array_image, -1, gaussian_filter)\n",
    "        \n",
    "        # Convert filtered image back to PIL format\n",
    "        filtered_image = Image.fromarray(filtered_gaussian_image)\n",
    "        \n",
    "        image_ref_modified = ImageTk.PhotoImage(filtered_image)  # Store the reference\n",
    "        canvas_modified.config(width=filtered_image.width, height=filtered_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "#median filter\n",
    "\n",
    "def median_filter():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "\n",
    "        # Apply the Median filter using cv2\n",
    "        median_filtered_image = cv2.medianBlur(array_image, 3)\n",
    "    \n",
    "        # Convert the filtered image back to PIL format\n",
    "        median_image = Image.fromarray(median_filtered_image)\n",
    "    \n",
    "        image_ref_modified = ImageTk.PhotoImage(median_image)  # Store the reference\n",
    "        canvas_modified.config(width=median_image.width, height=median_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Roberts filter\n",
    "def roberts_filter():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "\n",
    "        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "        roberts_filtered_image = cv2.filter2D(array_image, -1, kernel)\n",
    "        \n",
    "        roberts_image = Image.fromarray(roberts_filtered_image)\n",
    "        \n",
    "        image_ref_modified = ImageTk.PhotoImage(roberts_image)  # Store the reference\n",
    "        canvas_modified.config(width=roberts_image.width, height=roberts_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Sharpen image\n",
    "def sharpen_image():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "\n",
    "        # Define a sharpening kernel\n",
    "        sharpening_kernel = np.array([[0, -1, 0], \n",
    "                                      [-1, 5, -1], \n",
    "                                      [0, -1, 0]])\n",
    "        \n",
    "        sharpened_image = cv2.filter2D(array_image, -1, sharpening_kernel)\n",
    "    \n",
    "        # Convert the sharpened image back to PIL format\n",
    "        sharpened_image = Image.fromarray(sharpened_image)\n",
    "    \n",
    "        image_ref_modified = ImageTk.PhotoImage(sharpened_image)  # Store the reference\n",
    "        canvas_modified.config(width=sharpened_image.width, height=sharpened_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "        \n",
    "\n",
    "# Adjust brightness\n",
    "def adjust_brightness():\n",
    "    global modified_image, image_ref_modified\n",
    "    brightness = styled_input_dialog(\"Input\", \"Enter brightness level (0.0 to 10.0):\")\n",
    "    if brightness is not None:\n",
    "        brightness = float(brightness)\n",
    "        enhancer = ImageEnhance.Brightness(modified_image)\n",
    "        modified_image = enhancer.enhance(brightness)\n",
    "        image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Adjust contrast\n",
    "def adjust_contrast():\n",
    "    global modified_image, image_ref_modified\n",
    "    contrast = styled_input_dialog(\"Input\", \"Enter contrast level (0.0 to 10.0):\")\n",
    "    if contrast is not None:\n",
    "        contrast = float(contrast)\n",
    "        enhancer = ImageEnhance.Contrast(modified_image)\n",
    "        modified_image = enhancer.enhance(contrast)\n",
    "        image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Adjust color balance\n",
    "def adjust_color_balance():\n",
    "    global modified_image, image_ref_modified\n",
    "    color_factor = styled_input_dialog(\"Input\", \"Enter color factor (0.0 to 10.0):\")\n",
    "    if color_factor is not None:\n",
    "        color_factor = float(color_factor)\n",
    "        enhancer = ImageEnhance.Color(modified_image)\n",
    "        modified_image = enhancer.enhance(color_factor)\n",
    "        image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Save the modified image\n",
    "def save_image():\n",
    "    if modified_image is not None:\n",
    "        save_path = filedialog.asksaveasfilename(defaultextension=\".png\", filetypes=[(\"PNG files\", \"*.png\"), (\"JPEG files\", \"*.jpg\"), (\"All files\", \"*.*\")])\n",
    "        if save_path:\n",
    "            modified_image.save(save_path)\n",
    "            messagebox.showinfo(\"Image Saved\", f\"Image saved successfully to {save_path}\")\n",
    "    else:\n",
    "        messagebox.showwarning(\"No Image\", \"No modified image to save.\")\n",
    "\n",
    "# Reset the image to its original state\n",
    "def reset_image():\n",
    "    global modified_image, image_ref_modified\n",
    "    modified_image = original_image.copy()\n",
    "    image_ref_modified = ImageTk.PhotoImage(modified_image)\n",
    "    canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Segmentation\n",
    "\n",
    "def kmeans_segmentation():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "        pixel_vals = array_image.reshape((-1, 3))\n",
    "        pixel_vals = np.float32(pixel_vals)\n",
    "\n",
    "        # Define criteria, number of clusters(K) and apply KMeans\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "        k = 3  # You can adjust this for different segmentation results\n",
    "        _, labels, centers = cv2.kmeans(pixel_vals, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "        centers = np.uint8(centers)\n",
    "        segmented_image = centers[labels.flatten()]\n",
    "        segmented_image = segmented_image.reshape(array_image.shape)\n",
    "\n",
    "        kmeans_image = Image.fromarray(segmented_image)\n",
    "        image_ref_modified = ImageTk.PhotoImage(kmeans_image)\n",
    "        canvas_modified.config(width=kmeans_image.width, height=kmeans_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# GrabCut Segmentation\n",
    "def grabcut_segmentation():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "        mask = np.zeros(array_image.shape[:2], np.uint8)\n",
    "        \n",
    "        bgdModel = np.zeros((1, 65), np.float64)\n",
    "        fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "        rect = (50, 50, array_image.shape[1] - 100, array_image.shape[0] - 100)\n",
    "        cv2.grabCut(array_image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "        mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "        grabcut_image = array_image * mask2[:, :, np.newaxis]\n",
    "\n",
    "        grabcut_image = Image.fromarray(grabcut_image)\n",
    "        image_ref_modified = ImageTk.PhotoImage(grabcut_image)\n",
    "        canvas_modified.config(width=grabcut_image.width, height=grabcut_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "\n",
    "# Canny Edge Detection\n",
    "def canny_edge_detection():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image)\n",
    "        edges = cv2.Canny(array_image, 100, 200)\n",
    "\n",
    "        canny_image = Image.fromarray(edges)\n",
    "        image_ref_modified = ImageTk.PhotoImage(canny_image)\n",
    "        canvas_modified.config(width=canny_image.width, height=canny_image.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Thresholding Segmentation\n",
    "def thresholding_segmentation():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image.convert(\"L\"))  # Convert to grayscale\n",
    "        _, thresholded_image = cv2.threshold(array_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        thresholded_image_pil = Image.fromarray(thresholded_image)\n",
    "        image_ref_modified = ImageTk.PhotoImage(thresholded_image_pil)\n",
    "        canvas_modified.config(width=thresholded_image_pil.width, height=thresholded_image_pil.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "# Watershed Segmentation\n",
    "def watershed_segmentation():\n",
    "    global modified_image, image_ref_modified\n",
    "    if modified_image is not None:\n",
    "        array_image = np.array(modified_image.convert(\"RGB\"))\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(array_image, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        # Apply threshold\n",
    "        ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Noise removal\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "        \n",
    "        # Sure background area\n",
    "        sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "        \n",
    "        # Finding sure foreground area\n",
    "        dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "        ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "        \n",
    "        # Finding unknown region\n",
    "        sure_fg = np.uint8(sure_fg)\n",
    "        unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "        \n",
    "        # Marker labelling\n",
    "        ret, markers = cv2.connectedComponents(sure_fg)\n",
    "        markers = markers + 1\n",
    "        \n",
    "        # Mark the region of unknown with zero\n",
    "        markers[unknown == 0] = 0\n",
    "        \n",
    "        markers = cv2.watershed(array_image, markers)\n",
    "        array_image[markers == -1] = [255, 0, 0]  # Mark the boundaries\n",
    "        \n",
    "        watershed_image_pil = Image.fromarray(array_image)\n",
    "        image_ref_modified = ImageTk.PhotoImage(watershed_image_pil)\n",
    "        canvas_modified.config(width=watershed_image_pil.width, height=watershed_image_pil.height)\n",
    "        canvas_modified.create_image(0, 0, image=image_ref_modified, anchor=\"nw\")\n",
    "\n",
    "#------------------DEEP LEARNING STYLE TRANSFER\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "  \n",
    "    tensor_shape = tf.shape(tensor)\n",
    "    number_elem_shape = tf.shape(tensor_shape)\n",
    "    if number_elem_shape > 3:\n",
    "        assert tensor_shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return tf.keras.preprocessing.image.array_to_img(tensor) \n",
    "\n",
    "# Function to load an image \n",
    "def load_img(path_to_img):\n",
    "    \n",
    "    max_dim = 512\n",
    "    image = tf.io.read_file(path_to_img)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32) \n",
    "\n",
    "    shape = tf.shape(image)[:-1]\n",
    "    shape = tf.cast(shape, tf.float32)  \n",
    "    long_dim = max(shape)\n",
    "    scale = max_dim / long_dim\n",
    "\n",
    "    new_shape = tf.cast(shape * scale, tf.int32) \n",
    "\n",
    "    image = tf.image.resize(image, new_shape)\n",
    "    image = image[tf.newaxis, :]  \n",
    "    return image\n",
    "\n",
    "def clip_image_values(image, min_value=0.0, max_value=255.0):\n",
    "    \"\"\"Clips the pixel values of the image to stay within the valid range.\"\"\"\n",
    "    return tf.clip_by_value(image, clip_value_min=min_value, clip_value_max=max_value)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    '''Preprocesses the image to match the input requirements of the VGG19 model'''\n",
    "    image = tf.cast(image, tf.float32)  # Cast image to float32\n",
    "    image = tf.keras.applications.vgg19.preprocess_input(image)  \n",
    "    return image\n",
    "\n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "content_layers = ['block5_conv2']\n",
    "output_layers = style_layers + content_layers\n",
    "NUM_STYLE_LAYERS = len(style_layers)\n",
    "NUM_CONTENT_LAYERS = len(content_layers)\n",
    "\n",
    "def vgg_model(layer_names):\n",
    "    '''Creates a VGG model that returns the outputs of specific layers'''\n",
    "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model\n",
    "\n",
    "vgg = vgg_model(output_layers)\n",
    "\n",
    "def get_style_loss(features, targets, weight=1.0):\n",
    "    style_loss = tf.reduce_mean(tf.square(features - targets))\n",
    "    return weight * style_loss\n",
    "\n",
    "def get_content_loss(features, targets, weight=1.0):\n",
    "    content_loss = tf.reduce_sum(tf.square(features - targets))\n",
    "    return weight * content_loss\n",
    "\n",
    "def gram_matrix(input_tensor):\n",
    "    gram = tf.linalg.einsum('bijc,bijd->bcd', input_tensor, input_tensor)\n",
    "    input_shape = tf.shape(input_tensor)\n",
    "    height = input_shape[1]\n",
    "    width = input_shape[2]\n",
    "    num_locations = tf.cast(height * width, tf.float32)\n",
    "    scaled_gram = gram / num_locations\n",
    "    return scaled_gram\n",
    "\n",
    "def get_style_image_features(image, vgg_model):\n",
    "    preprocessed_style_image = preprocess_image(image)\n",
    "    outputs = vgg_model(preprocessed_style_image)\n",
    "    style_outputs = outputs[:NUM_STYLE_LAYERS]\n",
    "    gram_style_features = [gram_matrix(style_output) for style_output in style_outputs]\n",
    "    return gram_style_features\n",
    "\n",
    "def get_content_image_features(image, vgg_model):\n",
    "    preprocessed_content_image = preprocess_image(image)\n",
    "    outputs = vgg_model(preprocessed_content_image)\n",
    "    content_outputs = outputs[NUM_STYLE_LAYERS:]\n",
    "    return content_outputs\n",
    "\n",
    "def get_style_content_loss(style_targets, style_outputs, content_targets, content_outputs, style_weight, content_weight):\n",
    "    style_loss = tf.add_n([get_style_loss(style_output, style_target, style_weight) \n",
    "                           for style_output, style_target in zip(style_outputs, style_targets)])\n",
    "    \n",
    "    content_loss = tf.add_n([get_content_loss(content_output, content_target, content_weight) \n",
    "                             for content_output, content_target in zip(content_outputs, content_targets)])\n",
    "    \n",
    "    style_loss = style_loss * style_weight / NUM_STYLE_LAYERS\n",
    "    content_loss = content_loss * content_weight / NUM_CONTENT_LAYERS\n",
    "    \n",
    "    total_loss = style_loss + content_loss\n",
    "    return total_loss\n",
    "\n",
    "def calculate_gradients(image, style_targets, content_targets, style_weight, content_weight, var_weight, vgg_model):\n",
    "    with tf.GradientTape() as tape:\n",
    "        style_features = get_style_image_features(image, vgg_model)\n",
    "        content_features = get_content_image_features(image, vgg_model)\n",
    "        loss = get_style_content_loss(style_targets, style_features, content_targets, content_features, style_weight, content_weight)\n",
    "        gradients = tape.gradient(loss, image)\n",
    "    return gradients\n",
    "\n",
    "def update_image_with_style(image, style_targets, content_targets, style_weight, var_weight, content_weight, optimizer, vgg_model):\n",
    "    gradients = calculate_gradients(image, style_targets, content_targets, style_weight, content_weight, var_weight, vgg_model)\n",
    "    optimizer.apply_gradients([(gradients, image)])\n",
    "    image.assign(clip_image_values(image, min_value=0.0, max_value=255.0))\n",
    "\n",
    "def fit_style_transfer(style_image, content_image, style_weight=1e-2, content_weight=1e-4, var_weight=0, optimizer=None, epochs=1, steps_per_epoch=1, vgg=None, display_fn=None):\n",
    "    images = []\n",
    "    step = 0\n",
    "\n",
    "    if optimizer is None:\n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                initial_learning_rate=20.0,\n",
    "                decay_steps=100,\n",
    "                decay_rate=0.5\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if vgg is None:\n",
    "        raise ValueError(\"VGG model must be provided.\")\n",
    "\n",
    "    style_targets = get_style_image_features(style_image, vgg)\n",
    "    content_targets = get_content_image_features(content_image, vgg)\n",
    "\n",
    "    generated_image = tf.cast(content_image, dtype=tf.float32)\n",
    "    generated_image = tf.Variable(generated_image)\n",
    "\n",
    "    images.append(content_image)\n",
    "\n",
    "    for n in range(epochs):\n",
    "        for m in range(steps_per_epoch):\n",
    "            step += 1\n",
    "            update_image_with_style(generated_image, style_targets, content_targets, style_weight, var_weight, content_weight, optimizer, vgg)\n",
    "            print(\".\", end=\"\")\n",
    "            if (m + 1) % 10 == 0:\n",
    "                images.append(generated_image.numpy())\n",
    "\n",
    "        if display_fn:\n",
    "            display_image = tensor_to_image(generated_image)\n",
    "            display_fn(display_image)\n",
    "\n",
    "        images.append(generated_image.numpy())\n",
    "        print(f\"Train step: {step}\")\n",
    "\n",
    "    generated_image = tf.cast(generated_image, dtype=tf.float32)\n",
    "    return generated_image, images\n",
    "\n",
    "def select_image(image_type, window_context):\n",
    "   \n",
    "    filepath = filedialog.askopenfilename()\n",
    "    if filepath:\n",
    "        img = Image.open(filepath)\n",
    "        img = img.resize((150, 150), Image.Resampling.LANCZOS)\n",
    "\n",
    "        if image_type == 'content':\n",
    "            window_context['content_image_path'].set(filepath)\n",
    "            window_context['content_img_label'].imgtk = ImageTk.PhotoImage(img)\n",
    "            window_context['content_img_label'].configure(image=window_context['content_img_label'].imgtk)\n",
    "            window_context['content_img_label'].imgtk = window_context['content_img_label'].imgtk  \n",
    "\n",
    "        elif image_type == 'style':\n",
    "            window_context['style_image_path'].set(filepath)\n",
    "            window_context['style_img_label'].imgtk = ImageTk.PhotoImage(img)\n",
    "            window_context['style_img_label'].configure(image=window_context['style_img_label'].imgtk)\n",
    "            window_context['style_img_label'].imgtk = window_context['style_img_label'].imgtk  \n",
    "\n",
    "\n",
    "def start_style_transfer(window_context):\n",
    "   \n",
    "    content_image = load_img(window_context['content_image_path'].get())\n",
    "    style_image = load_img(window_context['style_image_path'].get())\n",
    "\n",
    "    style_weight = 2e-2\n",
    "    content_weight = 1e-2\n",
    "\n",
    "    adam = tf.optimizers.Adam(\n",
    "        tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=20.0,\n",
    "            decay_steps=100,\n",
    "            decay_rate=0.50\n",
    "        )\n",
    "    )\n",
    "\n",
    "    vgg = vgg_model(output_layers)\n",
    "\n",
    "    output_image, _ = fit_style_transfer(\n",
    "        style_image=style_image,\n",
    "        content_image=content_image,\n",
    "        style_weight=style_weight,\n",
    "        content_weight=content_weight,\n",
    "        var_weight=0,\n",
    "        optimizer=adam,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=10,\n",
    "        vgg=vgg\n",
    "    )\n",
    "\n",
    "    stylized_image_pil = tensor_to_image(output_image)\n",
    "    stylized_image_pil = stylized_image_pil.resize((150, 150), Image.Resampling.LANCZOS)\n",
    "\n",
    "    result_image_ctk = ImageTk.PhotoImage(stylized_image_pil)\n",
    "    window_context['result_img_label'].configure(image=result_image_ctk)\n",
    "    window_context['result_img_label'].imgtk = result_image_ctk  # Prevent garbage collection\n",
    "\n",
    "\n",
    "\n",
    "#----------------DEEP LEARNING ENDS\n",
    "\n",
    "#----deep learning gui begins\n",
    "def open_style_transfer_window():\n",
    "    style_window = ctk.CTkToplevel(root)\n",
    "    style_window.geometry(\"1920x1080\")\n",
    "    style_window.title(\"Neural Style Transfer\")\n",
    "\n",
    "    # Create a context dictionary to pass around the necessary UI elements\n",
    "    window_context = {\n",
    "        'content_image_path': ctk.StringVar(),\n",
    "        'style_image_path': ctk.StringVar(),\n",
    "        'content_img_label': None,\n",
    "        'style_img_label': None,\n",
    "        'result_img_label': None,\n",
    "    }\n",
    "\n",
    "    title_label = ctk.CTkLabel(style_window, text=\"Neural Style Transfer\", font=('Arial', 20))\n",
    "    title_label.pack(pady=20)\n",
    "\n",
    "    \n",
    "    content_btn = ctk.CTkButton(style_window, text=\"Select Content Image\", command=lambda: select_image('content', window_context))\n",
    "    content_btn.pack(pady=10)\n",
    "    window_context['content_img_label'] = ctk.CTkLabel(style_window, text=\"\")\n",
    "    window_context['content_img_label'].pack()\n",
    "\n",
    "    \n",
    "    style_btn = ctk.CTkButton(style_window, text=\"Select Style Image\", command=lambda: select_image('style', window_context))\n",
    "    style_btn.pack(pady=10)\n",
    "    window_context['style_img_label'] = ctk.CTkLabel(style_window, text=\"\")\n",
    "    window_context['style_img_label'].pack()\n",
    "\n",
    "    \n",
    "    start_btn = ctk.CTkButton(style_window, text=\"Start Style Transfer\", command=lambda: start_style_transfer(window_context))\n",
    "    start_btn.pack(pady=20)\n",
    "\n",
    "    window_context['result_img_label'] = ctk.CTkLabel(style_window, text=\"Result will be displayed here\")\n",
    "    window_context['result_img_label'].pack()\n",
    "\n",
    "#--- deep learning gui ends\n",
    "        \n",
    "\n",
    "# UI Elements\n",
    "left_frame = ctk.CTkScrollableFrame(root, width=200, height=600, corner_radius=0, bg_color=\"#333333\")  \n",
    "left_frame.pack(side=\"left\", fill=\"y\")\n",
    "\n",
    "canvas_original = ctk.CTkCanvas(root, width=500, height=600, bg=\"#ffffff\")  \n",
    "canvas_original.pack(side=\"left\", padx=10, pady=10)\n",
    "\n",
    "canvas_modified = ctk.CTkCanvas(root, width=500, height=600, bg=\"#ffffff\")  \n",
    "canvas_modified.pack(side=\"right\", padx=10, pady=10)\n",
    "\n",
    "# Add image button\n",
    "add_icon = ctk.CTkImage(dark_image=Image.open(\"icons/upload.png\"), size=(20, 20))     \n",
    "image_button = ctk.CTkButton(left_frame, text=\"Add Image\", command=add_image, image=add_icon)\n",
    "image_button.pack(pady=20)\n",
    "\n",
    "\n",
    "\n",
    "# Rotate image button\n",
    "rotate_icon = ctk.CTkImage(dark_image=Image.open(\"icons/rotate.png\"), size=(20, 20))\n",
    "rotate_button = ctk.CTkButton(left_frame, text=\"Rotate Image\", command=rotate_image, image=rotate_icon)\n",
    "rotate_button.pack(pady=10)\n",
    "\n",
    "\n",
    "# Crop image button\n",
    "crop_icon = ctk.CTkImage(dark_image=Image.open(\"icons/crop.png\"), size=(20, 20))\n",
    "crop_button = ctk.CTkButton(left_frame, text=\"Crop Image\", command=crop_image, image=crop_icon)\n",
    "crop_button.pack(pady=10)\n",
    "\n",
    "# Invert colors button\n",
    "invert_icon = ctk.CTkImage(dark_image=Image.open(\"icons/invert.png\"), size=(20, 20))  # Assuming you have an invert icon\n",
    "invert_button = ctk.CTkButton(left_frame, text=\"Invert Colors\", command=invert_colors, image=invert_icon)\n",
    "invert_button.pack(pady=10)\n",
    "\n",
    "\n",
    "# Adjust brightness button\n",
    "brightness_icon = ctk.CTkImage(dark_image=Image.open(\"icons/brightness.png\"), size=(20, 20))\n",
    "brightness_button = ctk.CTkButton(left_frame, text=\"Adjust Brightness\", command=adjust_brightness, image=brightness_icon)\n",
    "brightness_button.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Grayscale image button\n",
    "grayscale_icon = ctk.CTkImage(dark_image=Image.open(\"icons/grayscale.png\"), size=(20, 20))  # If you have a grayscale icon\n",
    "grayscale_button = ctk.CTkButton(left_frame, text=\"Convert to Grayscale\", command=convert_to_grayscale, image=grayscale_icon)\n",
    "grayscale_button.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#gaussian filter\n",
    "gaussian_icon = ctk.CTkImage(dark_image=Image.open(\"icons/gaussian.png\"), size=(20, 20))\n",
    "gaussian_filter_button = ctk.CTkButton(left_frame, text=\"Gaussian Filter\", command=gaussian_filter, image=gaussian_icon)\n",
    "gaussian_filter_button.pack(pady=10)\n",
    "\n",
    "#median filter\n",
    "median_icon = ctk.CTkImage(dark_image=Image.open(\"icons/graph.png\"), size=(20, 20))\n",
    "median_filter_button =ctk.CTkButton(left_frame, text=\"Median Blur\", command=median_filter, image=median_icon)\n",
    "median_filter_button.pack(pady=10)\n",
    "\n",
    "#roberts filter\n",
    "roberts_filter_button =ctk.CTkButton(left_frame, text=\"Roberts Image\", command=roberts_filter)\n",
    "roberts_filter_button.pack(pady=10)\n",
    "\n",
    "#sharpen image\n",
    "sharpen_icon = ctk.CTkImage(dark_image=Image.open(\"icons/sharpen.png\"), size=(20, 20))\n",
    "sharpen_button =ctk.CTkButton(left_frame, text=\"Sharpen Image\", command=sharpen_image,image=sharpen_icon)\n",
    "sharpen_button.pack(pady=10)\n",
    "\n",
    "# Adjust contrast button\n",
    "contrast_icon = ctk.CTkImage(dark_image=Image.open(\"icons/contrast.png\"), size=(20, 20))\n",
    "contrast_button = ctk.CTkButton(left_frame, text=\"Adjust Contrast\", command=adjust_contrast, image=contrast_icon)\n",
    "contrast_button.pack(pady=10)\n",
    "\n",
    "# Adjust color balance button\n",
    "filter_icon = ctk.CTkImage(dark_image=Image.open(\"icons/filter.png\"), size=(20, 20))\n",
    "color_balance_button = ctk.CTkButton(left_frame, text=\"Adjust Color Balance\", command=adjust_color_balance, image=filter_icon)\n",
    "color_balance_button.pack(pady=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add buttons for segmentation techniques\n",
    "kmeans_button = ctk.CTkButton(left_frame, text=\"K-Means Segmentation\", command=kmeans_segmentation)\n",
    "kmeans_button.pack(pady=10)\n",
    "\n",
    "grabcut_button = ctk.CTkButton(left_frame, text=\"GrabCut Segmentation\", command=grabcut_segmentation)\n",
    "grabcut_button.pack(pady=10)\n",
    "\n",
    "canny_button = ctk.CTkButton(left_frame, text=\"Canny Edge Detection\", command=canny_edge_detection)\n",
    "canny_button.pack(pady=10)\n",
    "\n",
    "threshold_button = ctk.CTkButton(left_frame, text=\"Thresholding Segmentation\", command=thresholding_segmentation)\n",
    "threshold_button.pack(pady=10)\n",
    "\n",
    "watershed_button = ctk.CTkButton(left_frame, text=\"Watershed Segmentation\", command=watershed_segmentation)\n",
    "watershed_button.pack(pady=10)\n",
    "\n",
    "#----deep larning \n",
    "\n",
    "open_style_transfer_btn = ctk.CTkButton(left_frame, text=\"Open Neural Style Transfer\", command=open_style_transfer_window)\n",
    "open_style_transfer_btn.pack(pady=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reset image button\n",
    "reset_icon = ctk.CTkImage(dark_image=Image.open(\"icons/undo.png\"), size=(20, 20))\n",
    "reset_button = ctk.CTkButton(left_frame, text=\"Reset Image\", command=reset_image, image=reset_icon)\n",
    "reset_button.pack(pady=20)\n",
    "\n",
    "# Save image button\n",
    "save_icon = ctk.CTkImage(dark_image=Image.open(\"icons/save.png\"), size=(20, 20))\n",
    "save_button = ctk.CTkButton(left_frame, text=\"Save Image\", command=save_image, image=save_icon)\n",
    "save_button.pack(pady=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99364a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
